<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>population-description</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar docked">


<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./population-description.html">4. Population description</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Home</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./website-information.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">How to use this website &amp; run SPSS</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./timetable.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Computer sessions timetable</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probability-sampling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1. Probability sampling</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">2. Introducing SPSS &amp; preparing data</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./introduction-to-spss.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2.1. Introducing SPSS</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preparing-a-dataset.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2.2. Preparing a dataset</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./sample-description.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3. Data exploration &amp; sample description</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./population-description.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">4. Population description</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./sample-size.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5. Sample size calculations</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">6. Bivariate tests for numerical variables</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./independent-t-test.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">6.1. Independent t-test</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./independent-t-test-skewed.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">6.2. Independent t-test with skewed data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./paired-t-test.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">6.3. Paired t-test</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">7. Bivariate tests for categorical variables</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chi-sq-independence.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">7.1. Chi-square test of independence</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chi-sq-goodness.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">7.2. Chi-square goodness of fit test</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./paired-categorical-test.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">7.3. Paired categorical variable test (McNemar’s test)</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">8. Regresson modelling</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./linear-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8.1. Linear regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./logistic-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8.2. Logistic regression</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./complex-survey-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">9. Complex survey design analysis</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#population-characteristics" id="toc-population-characteristics" class="nav-link active" data-scroll-target="#population-characteristics">Population characteristics</a></li>
  <li><a href="#rationale" id="toc-rationale" class="nav-link" data-scroll-target="#rationale">Rationale</a>
  <ul class="collapse">
  <li><a href="#descriptivesample-statistics-and-inferential-statistics" id="toc-descriptivesample-statistics-and-inferential-statistics" class="nav-link" data-scroll-target="#descriptivesample-statistics-and-inferential-statistics">Descriptive/sample statistics and inferential statistics</a></li>
  <li><a href="#confidence-intervals" id="toc-confidence-intervals" class="nav-link" data-scroll-target="#confidence-intervals">Confidence intervals</a></li>
  </ul></li>
  <li><a href="#practice" id="toc-practice" class="nav-link" data-scroll-target="#practice">Practice</a>
  <ul class="collapse">
  <li><a href="#scenario" id="toc-scenario" class="nav-link" data-scroll-target="#scenario">Scenario</a></li>
  <li><a href="#exercise-1-estimate-means-and-proportionspercentages-and-their-associated-95-confidence-intervals" id="toc-exercise-1-estimate-means-and-proportionspercentages-and-their-associated-95-confidence-intervals" class="nav-link" data-scroll-target="#exercise-1-estimate-means-and-proportionspercentages-and-their-associated-95-confidence-intervals">Exercise 1: estimate means and proportions/percentages and their associated 95% confidence intervals</a></li>
  <li><a href="#calculating-means-and-percentages-and-their-95-confidence-intervals-in-spss" id="toc-calculating-means-and-percentages-and-their-95-confidence-intervals-in-spss" class="nav-link" data-scroll-target="#calculating-means-and-percentages-and-their-95-confidence-intervals-in-spss">Calculating means and percentages and their 95% confidence intervals in SPSS</a></li>
  <li><a href="#additional-exercise-estimate-a-mean-and-a-percentages-and-their-associated-95-confidence-intervals" id="toc-additional-exercise-estimate-a-mean-and-a-percentages-and-their-associated-95-confidence-intervals" class="nav-link" data-scroll-target="#additional-exercise-estimate-a-mean-and-a-percentages-and-their-associated-95-confidence-intervals">Additional exercise: estimate a mean and a percentages and their associated 95% confidence intervals</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">



<section id="population-characteristics" class="level1">
<h1>Population characteristics</h1>
<hr>
<p>In this practical we will practice some common inferential analysis methods to estimate common univariate statistical properties of characteristics in a population.</p>
<p><br></p>
</section>
<section id="rationale" class="level1">
<h1>Rationale</h1>
<hr>
<p>Previously we saw how we can describe useful properties about univariate characteristics in a sample, such as the mean of a numerical variable and the percentage frequency of one level of a categorical variable. However, we are usually also interested in understanding the same types of useful statistical properties for certain variables in our target population, and that’s what we’ll do here. To do this, we want to compute confidence intervals to go with the sample statistics for our univariate characteristics of interest, where the sample statistics are our best estimates or point estimates of the population parameters of interest, and the confidence intervals enhance these estimates to allow us to make inferences about the likely value of those unknown population parameters. Usually, when we are estimating population parameters that are univariate characteristics we call the variables of interest outcome variables, but to be clear there’s nothing special about an outcome variable as opposed to any other variable, it’s just how we are using them.</p>
<p>If you are confident about the concepts of descriptive/sample statistics and inferential statistics, and with the idea and interpretation of a confidence interval, then feel free to skip to the exercise. However, if you are not confident about these topics then we suggest reading the following.</p>
<section id="descriptivesample-statistics-and-inferential-statistics" class="level2">
<h2 class="anchored" data-anchor-id="descriptivesample-statistics-and-inferential-statistics">Descriptive/sample statistics and inferential statistics</h2>
<details>
<summary>
Read/hide
</summary>
<p>It’s important to be very clear on the distinction between descriptive and inferential statistics.</p>
<p><strong>Descriptive statistics</strong></p>
<p>In summary, descriptive statistics, which are sometimes also called sample statistics or summary statistics, summarise statistical properties of individual variables (via “univariate” analyses) or summarise relationships between variables (typically via “bivariate” analyses) <strong>as they exist in your sample</strong>. For example, common univariate statistics are means, which summarise the typical value of a numerical variable, such the the mean systolic blood pressure in mmHg in the sample, and proportions/percentages, which summarise the frequency of occurrence of some event or condition, represented as one level of a binary/categorical variable, such as the proportion/percentage of smokers in the sample (as opposed to non-smokers).</p>
<p>Assuming you have no sources of bias in your study these descriptive statistics will reflect the truth about your sample. For example, if you have no bias then the true mean systolic blood pressure in mmHg in your sample will be the sample mean of all the systolic blood pressure values.</p>
<p><strong>Inferential statistics</strong></p>
<p>However, on their own these descriptive statistics do not allow you to make robust generalisations about the same statistical properties of individual variables or relationships between variables in your target population. Remember, when we are interested in the statistical properties of individual variables or relationships between variables in a target population we call the statistical quantities that reflect these properties “population parameters”, and we assume that they are fixed for the population and time point of interest. In theory, if we could take a census of the whole target population and measure our outcomes and relationships of interest without error then we could measure our population parameters without error. However, almost always our target population is far too large to do this and we need to take a sample, ideally using robust, representative, probability sampling methods, as we have seen. The equivalent sample statistic is then our best “point estimate” of the population parameter of interest, but as the name implies it is an estimate with an unquantified amount of error.</p>
<p>It is easy to see why this is the case. Let’s assume we want to infer the mean systolic blood pressure in mmHg for some target population that contains 100,000 individuals. Let’s assume we take a simple random sample of just 2 individuals and measure, without error, their systolic blood pressure in mmHg. The mean of these 2 systolic blood pressures values will be the true mean systolic blood pressure for our microscopically small sample of 2! However, does anyone believe that a mean of just two individuals’ systolic blood pressures, however representative they are, is likely to accurately reflect the true mean systolic blood pressure for the overall target population? Of course by chance it might be really accurate, but in general we’re very likely to get a sample that produces an estimated mean that is not reflective of the true population-level mean. And if we instead took another simple random sample of 2 other individuals and computed a new mean systolic blood pressure it would be very likely to be different from the first mean. So if each sample mean would vary, and we can usually only collect one sample, how can we tell how accurate our sample mean is?</p>
<p>This is the problem of sampling error and sample size. Each sample would likely produce a different estimate of our fixed population parameter, and depending on the sample size the estimate would be likely to vary more/less between each repeated sample.</p>
<p>Therefore, to let us infer the likely value of our population parameter we need to combine our sample statistic (i.e.&nbsp;our best point estimate) with some inferential measure. As we will discuss in the relevant lectures, this can be done most effectively by calculating the corresponding confidence intervals for the sample statistic, or a different approach involving hypothesis testing would be to compute an associated p-value. Note: this broad inferential approach is not just for when we are infering the statistical properties of individual variables in a target population, but also for when we are infering relationships in a target population. We combine the relevant sample statistic with a suitable inferential measure.</p>
<p><strong>Descriptive statistics and descriptive studies/research</strong></p>
<p>The terminology around descriptive statistics and descriptive studies can be a source of confusion. The key thing to remember is that <strong>descriptive statistics describe samples only</strong>, and are used in all studies to initially explore our data, plan our analyses, and describe the key characteristics of the sample so we can judge how representative our sample is compared to the target population in terms of these key characteristics. Whereas a descriptive study, or a study where one or more quantitative research questions are about description, is almost always about the goal of <strong>describing characteristics/relationships in a target population</strong> via sample and using inferential statistics (even if that target population is not clearly specified). You can certianly find studies that have only described a sample alone using sample statistics and no inferential measures, but in my experience that always seems to be because the authors have misunderstood statistical inference and don’t seem to understand what they are doing or how limited their results are.</p>
<p>So if studies say they are aiming to <em>describe</em> characteristics or relationships in a given target population, and they have taken a sample from that target population to do this, then if they know what they are doing then they mean that they are going to use inferential statistics (typically confidence intervals around point estimates) to try and infer the likely (but ultimately unknown) values for those characteristics/relationships in the target population.</p>
</details>
</section>
<section id="confidence-intervals" class="level2">
<h2 class="anchored" data-anchor-id="confidence-intervals">Confidence intervals</h2>
<details>
<summary>
Read/hide
</summary>
<p><strong>Interpretation</strong></p>
<blockquote class="blockquote">
<p>Note: formally the interpretation of a confidence interval applies to a fully defined target population that you have sampled using a probability sampling method. Once you start trying to interpret a confidence interval in relation to a target population that you haven’t sampled from, or based on an analysis of a sample taken using some kind of purposive approach, then strictly speaking there is no robust, mathematical basis for that interpretation. However, you can certainly think about interpreting a confidence interval in relation to a different target population that you didn’t sample from, and you can certainly calculate confidence intervals based on purposively sampled samples, but you need to carefully consider how these factors affect the robustness and validity of the interpretation.</p>
</blockquote>
<p>Confidence intervals take the form of a lower and upper value that surround the point estimate. For example, let’s say we estimate the mean age in a target population as 30, based on computing the mean age in a simple random sample from that population. Let’s assume we then compute a 95% confidence interval around that mean with lower and upper values of 25 and 35. We would usually write these statistics all together as:</p>
<blockquote class="blockquote">
<p>Mean age: 30 (95% CI: 25, 35)</p>
</blockquote>
<p>Where CI = confidence interval. Note, we separate the lower and upper interval via a comma not a hyphen “-”, as hyphens can be mistaken for negative symbols.</p>
<p>Strictly speaking confidence intervals are a mathematical statement about hypothetical resampling in relation to our point estimate of interest. Unfortunately, this can be quite a confusing, technical concept. More concretely, what this confidence interval is telling us is that if we were to repeat our random sampling process infinitely many times and each time we were to compute the mean age and its 95% confidence interval then 95% of those 95% confidence intervals would contain the true (but unknown) value of the mean age in the target population. Hence, we can never be certain what the exact mean age of the target population is based on the confidence interval, but it does give us an interval (i.e.&nbsp;a range of values) within which it is likely to lie. Yes, this is a frustratingly indirect statement about the true mean that we want to measure, but that is how the theory works, and that is the technically correct interpretation.</p>
<p>Note: many people, including many researchers/papers, would say we can be “95% confident” the true (but unknown) population parameter lies within the 95% confidence interval. However, technically speaking this phrase “95% confident” doesn’t have any precise, concrete, mathematical meaning. Also, the probability that the population parameter of interest lies within a given confidence interval is either 100% or 0%. We could know which of these scenarios was true if we were able to measure the whole population and calculate the population parameter. So it’s pretty questionable whether this is a valid or useful approach, but you will see it often.</p>
<p>Note: There is nothing special about a 95% confidence interval compared to a higher or lower level of confidence, such as a 90% confidence interval. However, for a given variable as you increase the confidence level the interval increases. For example, for our hypothetical situation above we may find a 99% confidence interval around our mean age of 30 is 10 and 50. While we may find a 80% confidence interval would be from 28 to 32. The interpretation remains the same. For example, for 99% confidence intervals we obtain confidence interval limits that, if we were to repeat the sampling and estimation and infinite number of times, would contain the true population parameter value 99% of the time.</p>
<p>Therefore, there is a trade-off in the usefulness of the confidence interval as you vary the confidence level. Too high a confidence level results in a high level of certainty but for a very wide interval, while too low a confidence level results in a low level of certainty but for a very narrow (precise) interval. The widespread use of 95% confidence intervals in the health sciences is largely just a convention, i.e.&nbsp;due to tradition. For a given confidence level, all else being equal, if we increase the sample size the interval will become narrower. Therefore, if you have sufficient sample size then a higher level of confidence would clearly be preferable.</p>
<blockquote class="blockquote">
<p>Note: it is absolutely critically important to be aware, and when interpreting a confidence interval to always remember that, the accuracy or validity of the above interpretation of a confidence interval depends <em>entirely</em> on there being no bias in the study. Confidence intervals quantify the amount of variation in the sample data relative to the sample size. So they allow us to decide how closely we are likely to have estimated the population parameter of interest given the sample size and variation in the outcome, which may come from the fundamental/natural variation in the outcome’s values in that target population, and some extra random variation may come from non-differential error like truely random measurement error.</p>
</blockquote>
<blockquote class="blockquote">
<p>However, confidence intervals tell you <strong>nothing</strong> about any sources of bias, such as selection bias, or any non-random (differential) sources of error, like non-random missing data or non-random measurement error. Remember, study bias can occur throughout the entire study cycle, from planning the data collection tools through to reporting the study results. Therefore, if the study results are affected by any sources of bias, which is inevitable to some extent, then the accuracy and validity of the confidence interval will be affected, usually to an unknown extent. For example, using the age example from before: if older people were less likely to agree to participate in the survey that collected their age data, then this would be a form of selection bias, and the resulting 95% confidence interval and point estimate for the mean age of that population would be skewed downwards, and the confidence intervals may no longer include the true (but unknown) value of the mean age in the population 95% of the time. Again, it is usually not possible to estimate the effect of such biases, so they must be judged more qualitatively via rigorously exploring and understanding all possible sources of bias and the likely size of their impact.</p>
</blockquote>
<p><strong>Computing confidence intervals</strong></p>
<p>Don’t worry: we will leave the computation of our confidence intervals up to the software. However, when computing a confidence interval we need to make an assumption about the type of probability distribution that we assume the sample statistic of interest comes from (i.e.&nbsp;the probability distribution we would see if we were to take many repeated samples, calculate the sample statistic each time, and plot their distribution on a histogram). Here we will just be focusing on estimating population-level means for numerical outcomes and percentages for the levels of a binary/categorical outcome.</p>
<p>For continuous variables a reasonable assumption about the appropriate probability distribution will often be the normal distribution, and if we plot the distribution of the variable’s values and they are approximately normal it is usually safe to assume a normal distribution will be appropriate for the confidence interval. If the distribution is skewed, as will usually be the case for discrete variables such as counts, we can try and transform the distribution of the outcome variable before computing the confidence interval, while still assuming a normal distribution when computing the confidence interval, or we can use a more appropriate distribution, but that is beyond this course.</p>
<p>For binary/categorical variables you can also assume a normal distribution, even though this will never be correct, as long as it is approximately correct. When the percentage being estimate isn’t too small or too large, then the normal distribution is usually an okay approximation. “Too small” and “too large” are usually taken to be &gt;10% and &lt;90%, but these are just really rough rules of thumb. However, we can compute confidence intervals that make assumptions about the likely probability distribution of the sample statistic that are more appropriate for binary/categorical variables. There are actually many such possible methods, with little clear evidence on which is best and under what circumstances. We will look at this in a bit more detail in the exercise.</p>
</details>
<p><br></p>
</section>
</section>
<section id="practice" class="level1">
<h1>Practice</h1>
<hr>
<section id="scenario" class="level2">
<h2 class="anchored" data-anchor-id="scenario">Scenario</h2>
<p>You and your colleagues have been tasked by the Kapilvastu district authorities in Nepal to help them understand the problem of high blood pressure and hypertension, and the associations between socio-demographic and health related characteristics and blood pressure level/hypertension. You have carried out a cross-sectional survey to address these aims, and collected data on systolic blood pressure, common socio-demographic characteristics, and some additional health-related characteristics. So far, you have cleaned and prepared the data, and computed descriptive statistics for key characteristics. As per your statistical analysis plan you now need to use the data to estimate the likely mean systolic blood pressure and prevalence (%) of hypertension for the target population.</p>
</section>
<section id="exercise-1-estimate-means-and-proportionspercentages-and-their-associated-95-confidence-intervals" class="level2">
<h2 class="anchored" data-anchor-id="exercise-1-estimate-means-and-proportionspercentages-and-their-associated-95-confidence-intervals">Exercise 1: estimate means and proportions/percentages and their associated 95% confidence intervals</h2>
<blockquote class="blockquote">
<p>Aim: estimate the mean systolic blood pressure (mmHg) and the prevalence of hypertension and their associated 95% confidence intervals to allow statistical inferences to be drawn about the typical level of systolic blood pressure and the prevalence of hypertension in the target population.</p>
</blockquote>
<ul>
<li><p>First, load the analysis-ready “SBP data final.sav” SPSS dataset.</p></li>
<li><p>Next, follow the instructions below on how to compute two common univariate inferential statistics for numerical and categorical variables, specifically means and percentages, with associated confidence intervals to allow inference about these measures in the target population.</p></li>
</ul>
</section>
<section id="calculating-means-and-percentages-and-their-95-confidence-intervals-in-spss" class="level2">
<h2 class="anchored" data-anchor-id="calculating-means-and-percentages-and-their-95-confidence-intervals-in-spss">Calculating means and percentages and their 95% confidence intervals in SPSS</h2>
<p>Sorry: at present there is no video-based set of instructions for this method.</p>
<p><strong>Written instructions: calculating means, percentages and their 95% confidence intervals in SPSS</strong></p>
<details>
<summary>
Read/hide
</summary>
<p><strong>Computing means and their 95% confidence intervals for continuous/discrete numerical variables with approximately normal distributions</strong></p>
<ul>
<li><p>To compute a confidence interval for any sample statistic requires us to make an assumption about the probability distribution we believe the sampling distribution of the sample statistic to have come from. We can make this decision based on our knowledge of the likely data generating process and the shape of the distribution (as visualised via a histogram). Below we will check that the data are approximately normally distributed.</p></li>
<li><p>When a numerical variable is approximately normal we can usually safely compute a confidence interval based on a normal distribution (i.e.&nbsp;we are unlikely to go too far wrong and compute a very biased confidence interval if this is the case). However, we will actually compute one based on a t-distribution. This is because a t-distribution is appropriate for continuous data that follow a very similar symmetrical, bell-curve shape as the normal distribution, but with the advantage that it allows for more variation at smaller sample sizes (thicker tails to the distribution), resulting in less risk of bias. Technically, if you use a normal distribution to compute a confidence interval this is only valid when the sample size is infinite, and at larger sample sizes the normal distribution and the t-distribution become equivalent, so there is no real reason not to use the t-distribution over the normal when possible.</p></li>
</ul>
<blockquote class="blockquote">
<p>Note: technically speaking we are just considering analytical confidence intervals here. However, there are empirical approaches such as bootstrap confidence intervals, which you may can read a bit about <a href="https://acclab.github.io/bootstrap-confidence-intervals.html">here</a></p>
</blockquote>
<ul>
<li><p>So let’s check that the variable is approximately normally distributed, otherwise the mean may not be the best measure of the typical value of the variable, and its 95% confidence intervals would not be accurate (technically speaking they may under or over cover the true interval on average). We’ll use the salt variable, which measures each individual’s reported typical salt consumption per day in grams.</p></li>
<li><p>From the main menu go to: <mark>Graphs &gt; Legacy Dialogues &gt; Histogram</mark> Then in the <mark>Histogram</mark> tool click on the <mark>salt</mark> variable and add it to the <mark>Variable:</mark> box by clicking the blue arrow next to the box. Tick the <mark>Display normal curve</mark> box below. This will display a theoretical normal distribution curve based on the mean and SD of the variable, which helps you to see how closely the data match the distribution we would expect if they were normally distributed. Then just click <mark>OK</mark>.</p></li>
<li><p>What does the distribution of the data look like? I would say there is clearly some right skew, but it’s not huge and we can probably ignore it without causing too much bias to our results (certainly for the purposes of this demonstration).</p></li>
<li><p>Now let’s compute the mean of the variable and a t-based 95% confidence interval to allow us to make a statistical inference about the likely value of the true (but unknown) mean salt intake per day in the target population.</p></li>
<li><p>To compute our t-based 95% confidence intervals we will actually tell SPSS to do a one-sample t-test. We cover other t-tests in section 5, but we don’t actually look at the one-sample t-test as it is rarely used. If you wish to read about it a brief overview with SPSS instructions is <a href="https://statistics.laerd.com/spss-tutorials/one-sample-t-test-using-spss-statistics.php">here</a>. However, for our purposes we are simply using the one-sample t-test as a way to get SPSS to compute the mean of a variable plus its 95% confidence interval assuming (i.e using) a t-distribution.</p></li>
<li><p>To do this from the menu go: <mark>Analyze &gt; Compare Means &gt; One-Sample T Test</mark>. Then add the <mark>salt</mark> variable into the <mark>Variables:</mark> box using the arrow and then click <mark>OK</mark>.</p></li>
<li><p>You will get three tables returned in the results window. The “One-Sample Statistics” table presents the sample size for the variable, which is useful because you should always present the sample size (i.e.&nbsp;count) for any estimate and the relative frequency (e.g.&nbsp;percentage) of complete/missing data for the variable.</p></li>
</ul>
<blockquote class="blockquote">
<p>Note: by default SPSS removes any observations from the variable with missing values when computing the results.</p>
</blockquote>
<ul>
<li>You can then look at the “One-Sample Test”. The columns we are interested in are the “Mean Difference”, which actually represents the mean. The reason for this is that technically the one-sample t-test compares the mean of the variable to an assumed population mean, which by default SPSS sets as 0 (you can alter it on the <mark>One-Sample T Test</mark> tool). Therefore, the variable’s mean - 0 is just the variables mean. You can also see the sample mean or point estimate of the population mean in the “One-Sample Statistics” table. Then finally we can see the t-based 95% lower and upper confidence intervals under the “95% Confidence Interval of the Difference” “Lower” and “Upper” columns.</li>
</ul>
<p><strong>Computing proportions/percentages and their 95% confidence intervals for categorical variables</strong></p>
<blockquote class="blockquote">
<p>Note: this approach is applicable to both binary variables or categorical variables with three or more category levels. However, in the case of a categorical variable with three or more category levels we actually just treat each category level as a separate binary variable in practice. For example, for the variable “education level” with category levels “none”, “primary”, and “more than primary” we estimate the proportion/percentage of individuals in the 1) “none” category vs “primary or more than primary”, 2) the “primary” category vs “none or more than primary”, and 3) the “more than primary” vs “none or primary”.</p>
</blockquote>
<ul>
<li><p>As above, to compute a confidence interval requires an appropriate probability distribution given the data. Clearly, a binary variable cannot formally be normally distributed: it can only take values of 0 and 1. However, as long as the underlying proportion is not “too extreme” we can actually treat it as an approximately normally distributed variable and compute normal-based confidence intervals. By “too extreme” the usual rule of thumb is the proportion for the variable must be &gt;0.1 and &lt;0.9. Beyond these limits the implied distribution becomes too non-normal for the approximation to be useful. For example, the lower/upper confidence interval will often be &lt;0 or &gt;1, and the bias in the accuracy of the confidence interval’s coverage becomes more substantial.</p></li>
<li><p>Alternatively and more appropriately, we can use a probability distribution formally applicable to a binary variable and our assumed data generating process, such as the binomial distribution. Generally, such a confidence interval is called a binomial proportion confidence interval.</p></li>
<li><p>Unlike for numeric variables that are approximately normal there are actually a large number of different approaches available though, and there is a surprisingly limited amount of research comparing these methods under different situations. However, the current rough consensus appears to be that the “Wilson score interval” method with the continuity correction generally does well. There is a Wikipedia page with a great summary of the situation [here] (https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval#Comparison_and_discussion).</p></li>
<li><p>SPSS offers the option to calculate a big range of these different binomial proportion confidence intervals all at the same time. Let’s see how we can do this for a categorical variable with three category levels for each category level.</p></li>
<li><p>From the menu go <mark>Analyze &gt; Compare Means &gt; One-Sample Proportions</mark>. Then add the ses variable from the [Variables:] box into the <mark>Test Variable(s):</mark> box using the blue arrow.</p></li>
<li><p>Next click on the button labelled <mark>“Confidence intervals”</mark> at the top right. Then under <mark>Select Type(s)</mark> tick <mark>Clopper-Pearson (“Exact”)</mark>, which is based directly on the binomial distribution, <mark>Wald</mark>, which just uses the normal distribution (often called normal approximation confidence intervals), <mark>Wilson Score</mark> and lastly <mark>Wilson Score (Continuity Corrected)</mark>. Then click <mark>Continue</mark>.</p></li>
<li><p>Now we need to decide which category level we want to calculate our proportion and confidence intervals for. The ses variable has three categories coded 1, 2 and 3, corresponding to low, medium and high socio-economic status.</p></li>
<li><p>Let’s look at low status first. In the <mark>Define Success</mark> box select the <mark>Value(s)</mark> button and in the box to left of the button enter the value 1 (low socio-economic status). Then click <mark>OK</mark>.</p></li>
<li><p>All the results we want are in the “One-Sample Proportions Confidence Intervals” table. As you can see the results for each confidence interval method are on a separate row, and you can see which method is on which row under the “Interval Type” column. Under the “Observed” heading there are three columns giving the number of “Successes”, which means the count of observations (i.e.&nbsp;individuals) in the category we selected, the number of “Trials”, which just means the number of observations or the sample size of the variable, and the corresponding “Proportion”. You can of course multiply this by 100 to convert to the percentage scale. We then have the lower and upper 95% confidence intervals under the correspondingly named final two columns. As you can see for this variable and these methods they actually give very similar results, and indeed the method using the normal approximation (“Wald”) is just as good as the other methods.</p></li>
<li><p>You could then repeat this process for the other category levels in the ses variable by simply changing the value in the <mark>Define Success: Value(s):</mark> box, but feel free to move onto the exercise if you don’t feel the need to try this now.</p></li>
</ul>
<blockquote class="blockquote">
<p>Note: if you have a categorical variable coded with letters or words instead of numbers you can also just enter the relevant letter or word into the <mark>Define Success: Value(s):</mark> box.</p>
</blockquote>
</details>
</section>
<section id="additional-exercise-estimate-a-mean-and-a-percentages-and-their-associated-95-confidence-intervals" class="level2">
<h2 class="anchored" data-anchor-id="additional-exercise-estimate-a-mean-and-a-percentages-and-their-associated-95-confidence-intervals">Additional exercise: estimate a mean and a percentages and their associated 95% confidence intervals</h2>
<ul>
<li>Open the “Exercises.docx” document and scroll to the “Estimating key population characteristics: blood pressure and hypertension” section. Using the methods practiced above calculate the mean blood pressure and its 95% confidence intervals and the prevalence of hypertension (as a percentage) and its 95% confidence intervals and record them in the space indicated. As per the instructions in the Exercises document, for the mean estimate calculate the confidence intervals using the t-based method and for the prevalence estimate calculate the confidence intervals using the Wilson Score method.</li>
</ul>
<p>You can check your answers below once you have completed the exercise:</p>
<details>
<summary>
Read/hide
</summary>
<p><strong>Systolic blood pressure (mmHg)</strong></p>
<ul>
<li>Population mean systolic blood pressure (mmHg): 126.5 (95% CI: 124.9, 128.2)</li>
<li>Sample size for estimate: 543</li>
</ul>
<p><strong>Hypertension</strong></p>
<ul>
<li>Population prevalence (%) of hypertension: 25% (95% CI: 21.6%, 28.9%)</li>
<li>Frequency and sample size for estimate: 136/543</li>
</ul>
</details>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>
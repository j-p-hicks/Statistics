<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>logistic-regression</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./14-linear-regression.html">7. Regresson modelling</a></li><li class="breadcrumb-item"><a href="./15-logistic-regression.html">7.2. Logistic regression</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Home</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1-website-information.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1. How to use this website</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">2. Sampling and sample size</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2-probability-sampling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2.1. Probability sampling</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3-sample-size.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2.2. Sample size</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">3. Introducing SPSS &amp; preparing data</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./4-introduction-to-spss.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3.1. Introducing SPSS</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./5-preparing-a-dataset.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3.2. Preparing a dataset</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">4. Data exploration, sample &amp; population characteristics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./6-describing-a-dataset.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4.1 Data exploration &amp; sample characteristics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./7-describing-a-population.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4.2. Population characteristics</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">5. Statistical tests for numerical variables</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./8-independent-t-test.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5.1. Independent t-test</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./9-independent-t-test-skewed.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5.2. Independent t-test with skewed data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-paired-t-test.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5.3. Paired t-test</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
 <span class="menu-text">6 Statistical tests for categorical variables</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11-chi-sq-independence.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">6.1. Chi-square test of independence</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12-chi-sq-goodness.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">6.2. Chi-square goodness of fit test</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13-paired-categorical-test.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">6.3. Paired categorical variable test (McNemar’s test)</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
 <span class="menu-text">7. Regresson modelling</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14-linear-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">7.1. Linear regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15-logistic-regression.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">7.2. Logistic regression</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16-complex-survey-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8. Complex survey design analysis</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#multiple-binary-logistic-regression" id="toc-multiple-binary-logistic-regression" class="nav-link active" data-scroll-target="#multiple-binary-logistic-regression">Multiple binary logistic regression</a>
  <ul class="collapse">
  <li><a href="#overview" id="toc-overview" class="nav-link" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#scenario" id="toc-scenario" class="nav-link" data-scroll-target="#scenario">Scenario</a></li>
  <li><a href="#modelling-process" id="toc-modelling-process" class="nav-link" data-scroll-target="#modelling-process">Modelling process</a></li>
  <li><a href="#step-1-explore-the-data" id="toc-step-1-explore-the-data" class="nav-link" data-scroll-target="#step-1-explore-the-data">Step 1: explore the data</a>
  <ul class="collapse">
  <li><a href="#numerical-independent-variables" id="toc-numerical-independent-variables" class="nav-link" data-scroll-target="#numerical-independent-variables">Numerical independent variables</a></li>
  <li><a href="#categorical-independent-variables" id="toc-categorical-independent-variables" class="nav-link" data-scroll-target="#categorical-independent-variables">Categorical independent variables</a></li>
  <li><a href="#cell-frequencies" id="toc-cell-frequencies" class="nav-link" data-scroll-target="#cell-frequencies">Cell frequencies</a></li>
  </ul></li>
  <li><a href="#step-2-run-the-logistic-regression-model" id="toc-step-2-run-the-logistic-regression-model" class="nav-link" data-scroll-target="#step-2-run-the-logistic-regression-model">Step 2: run the logistic regression model</a></li>
  <li><a href="#step-3-check-the-assumptions-of-the-logistic-regression" id="toc-step-3-check-the-assumptions-of-the-logistic-regression" class="nav-link" data-scroll-target="#step-3-check-the-assumptions-of-the-logistic-regression">Step 3: check the assumptions of the logistic regression</a></li>
  <li><a href="#step-4-consider-additional-problems" id="toc-step-4-consider-additional-problems" class="nav-link" data-scroll-target="#step-4-consider-additional-problems">Step 4: consider additional problems</a></li>
  <li><a href="#step-5-understand-the-results-tables-and-extract-the-key-results" id="toc-step-5-understand-the-results-tables-and-extract-the-key-results" class="nav-link" data-scroll-target="#step-5-understand-the-results-tables-and-extract-the-key-results">Step 5: understand the results tables and extract the key results</a></li>
  <li><a href="#step-6-report-and-interpret-the-results" id="toc-step-6-report-and-interpret-the-results" class="nav-link" data-scroll-target="#step-6-report-and-interpret-the-results">Step 6: report and interpret the results</a>
  <ul class="collapse">
  <li><a href="#understanding-and-interpreting-odds-ratios" id="toc-understanding-and-interpreting-odds-ratios" class="nav-link" data-scroll-target="#understanding-and-interpreting-odds-ratios">Understanding and interpreting odds ratios</a></li>
  <li><a href="#categorical-variables" id="toc-categorical-variables" class="nav-link" data-scroll-target="#categorical-variables">Categorical variables</a></li>
  <li><a href="#numerical-variables" id="toc-numerical-variables" class="nav-link" data-scroll-target="#numerical-variables">Numerical variables</a></li>
  <li><a href="#practical-importance" id="toc-practical-importance" class="nav-link" data-scroll-target="#practical-importance">Practical importance</a></li>
  <li><a href="#non-significant-results" id="toc-non-significant-results" class="nav-link" data-scroll-target="#non-significant-results">“Non-significant results”</a></li>
  <li><a href="#regression-tables" id="toc-regression-tables" class="nav-link" data-scroll-target="#regression-tables">Regression tables</a></li>
  <li><a href="#methods" id="toc-methods" class="nav-link" data-scroll-target="#methods">Methods</a></li>
  </ul></li>
  <li><a href="#exercise-multiple-logistic-regression" id="toc-exercise-multiple-logistic-regression" class="nav-link" data-scroll-target="#exercise-multiple-logistic-regression">Exercise: multiple logistic regression</a></li>
  <li><a href="#next-steps-optional" id="toc-next-steps-optional" class="nav-link" data-scroll-target="#next-steps-optional">Next steps (optional)</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">



<section id="multiple-binary-logistic-regression" class="level1">
<h1>Multiple binary logistic regression</h1>
<section id="overview" class="level2">
<h2 class="anchored" data-anchor-id="overview">Overview</h2>
<p>Like multiple linear regression multiple binary logistic regression allows us to analyse the relationships between any number of continuous and/or categorical independent variables and an outcome, but unlike multiple linear regression the outcome in multiple binary logistic regression must be binary. Like with linear regression “simple logistic regression” may be a term used to refer to logistic regression with one independent variable only, while “multiple linear regression” refers to including more than one independent variable, but there’s no qualitative difference, and we’ll just refer to “logistic regression” from here on. Also, as touched on in the lecture there are different versions or extension of binary logistic regression like multinomial logistic regression for categorical outcomes with any number of category levels, but as these are more advanced we will not be looking at them further. Therefore, because “binary logistic regression” is far more commonly used/seen than any other form of logistic regression we’ll just refer to it as logistic regression from here on, which is common practice (i.e.&nbsp;if you see “logistic regression” in the literature you can assume it’s referring to binary logistic regression).</p>
<p>You can actually analyse binary outcomes using linear regression, and you will sometimes see such analyses in the literature (sometimes called a “linear probability model”) and you can often get reasonably useful (i.e.&nbsp;reasonably accurate/unbiased) results. However, generally this is not recommended because of the often substantial disadvantages and problems with this approach. For example, the model predictions may range outside 0-1 (the only values your outcome can take in reality when viewed as a probability of the event occurring), and your inferences are likely to be biased because the assumptions of linear regression cannot be met in such a situation, producing biased confidence intervals and p-values. Although logistic regression is more complex mathematically the basic idea of creating a linear model (where the terms are additive) with numerical or categorical independent variables is the same, although the interpretation of the terms differs substantially.</p>
</section>
<section id="scenario" class="level2">
<h2 class="anchored" data-anchor-id="scenario">Scenario</h2>
<p>We will use almost exactly the same scenario as for the linear regression practical, using the SBP final dataset again. However, now we wish to understand the likely causes of variation in individuals’ <em>hypertension status</em> (rather than their systolic blood pressure), or more generally the likelihood of having hypertension, where we define hypertension as having a systolic blood pressure ≥140 mmHg, using the data collected in the SBP dataset. Refer to the “The datasets” section within the “Introduction to SPSS” section for full details if you need a full reminder, but briefly this dataset contains data on 556 individuals who were (hypothetically speaking!) sampled in a cross-sectional survey, and had data collected on their systolic blood pressure plus certain socio-demographic (age, sex, socio-economic status) and health characteristics (BMI, salt intake and ACE inhibitor usage).</p>
</section>
<section id="modelling-process" class="level2">
<h2 class="anchored" data-anchor-id="modelling-process">Modelling process</h2>
<p>We will use an almost identical modelling process to that used in the linear regression practical, loosely following a causal inference inspired approach, but in practice for simplicity building one model and interpreting all the independent variables causally. As discussed in the “Overview with a focus on causal inference from observational data” section in the “Inferential analysis 5: multiple regression” section, we will assume, based on existing theory/evidence and plausible, critical thinking, that all our measured independent variables are all likely causes of variation in individuals’ hypertension status, which collectively simultaneously act as a sufficient adjustment set when interpreting each independent variable’s relationship with the outcome causally. That is, we will just create one logistic regression model containing all the independent variables and assume that this model represents the same sufficient adjustment set for each independent variable (i.e.&nbsp;when interpreting the effect of each independent variable causally we will assume all other variables in the model are confounders of that relationship that require adjusting for to obtain an unbiased estimate of the focal causal effect). In reality if we were doing this we should start by deciding which focal relationships of interest we were interested in, which may well not be all of our collected independent variables, and for each focal relationship of interest we should define a sufficient adjustment set which may well differ from the sufficient adjustment set of other focal relationships of interest. This would typically be a big and time consuming process requiring a lot of careful critical thought and research/subject matter knowledge.</p>
<ul>
<li>Load the “SBP data final.sav” dataset.</li>
</ul>
</section>
<section id="step-1-explore-the-data" class="level2">
<h2 class="anchored" data-anchor-id="step-1-explore-the-data">Step 1: explore the data</h2>
<p><a href="https://youtu.be/uMGDhnJyl7I">Video instructions: explore the data for a logistic regression</a></p>
<p><strong>Written instructions: explore the data for a logistic regression</strong></p>
<details>
<summary>
Read/hide
</summary>
<p>The same basic reasoning applies to our data exploration process as with the linear regression modelling process, so refer back to the “Step 1: explore the data” section in the linear regression practical if you want a reminder of the theory/justification for the following data exploration process.</p>
<p>In practical terms though we would examine the distribution of each variable on its own using the same methods discussed in the linear modelling practical, but when examining the relationships between the outcome and each independent variable we would have to use different graphical approaches.</p>
<section id="numerical-independent-variables" class="level3">
<h3 class="anchored" data-anchor-id="numerical-independent-variables">Numerical independent variables</h3>
<p>Specifically, as we have a binary outcome when exploring the relationship between numerical independent variables and our binary outcome we have to use a form of barchart, where we first create a “binned” or grouped version of our numerical independent variable (i.e.&nbsp;a new variable which takes a single value for a range of values of the original independent variable).</p>
<p>Let’s see how to do this for bmi. First create the binned independent variable.</p>
<ul>
<li>From the main menu go: <mark>Transform &gt; Visual Binning</mark>. Add bmi to the <mark>Variables to Bin:</mark> box and click <mark>Continue</mark>. At the top of the window that apppears look for the <mark>Name:</mark> fields and in the editable field called <mark>Binned Variable:</mark> give your new binned variable a name, e.g.&nbsp;bmi_bin. Then at the bottom right click on the <mark>Make Cutpoints…</mark> button. In the middle of the tool window click the <mark>Equal Percentiles Based on Scanned Cases</mark> option and in the <mark>Intervals - fill in either field</mark> are click on the <mark>Number of Cutpoints:</mark> box and enter a suitable number of cutpoints. It’s hard to know what is a suitable number but typically the more bins the better, as you can see relationships at a finer scale, but for more bins you need more data (sample size). For bmi let’s choose 15, but you can always remake this variable with more/fewer bins as needed. Therefore, enter 15 in this box and then click <mark>Apply</mark> at the bottom. Then click the <mark>Make Labels</mark> button just below the <mark>Make Cutpoints…</mark> button and then click <mark>OK</mark>. Click <mark>OK</mark> on the information box that appears.</li>
</ul>
<p>Now we can plot the mean of our binary outcome, which is equivalent to the proportion/percentage, for every bin we’ve just created, using a type of barchart, although we’ll use a “histogram” tool to create it.</p>
<ul>
<li>From the main menu go: <mark>Graphs &gt; Chart Builder</mark>. If an information box appears saying “Before you use this dialogue…” just click <mark>OK</mark>. Now in the <mark>Gallery</mark> tab at the middle left click on <mark>Histogram</mark> and then double click on the leftmost picture of a graph (Simple Histogram) to add it to the plot. Next drag the htn variable from the <mark>Variables:</mark> box onto the <mark>Y-Axis?</mark> dotted box on the chart image. Similarly, drag the bmi_bin variable onto the <mark>X-Axis?</mark> box. Look to the right of the tool window at the <mark>Element Properties</mark> tab in the <mark>Statistics</mark> box. You should see a drop down menu under <mark>Statistic:</mark>. This should already read “Mean”, but if not click on it and select mean. This tells SPSS to calculate the mean of the Y-axis variable, htn, for each value of the X-axis variable, which are now repeated when in each bin. Now just click <mark>OK</mark>.</li>
</ul>
<p>What can you see?</p>
<p>What does the barchart of BMI vs hypertension show?</p>
<details>
<summary>
Read/hide
</summary>
<p>There appears to be a fairly linear increase in the proportion of individuals with hypertension as BMI values increase.</p>
</details>
</section>
<section id="categorical-independent-variables" class="level3">
<h3 class="anchored" data-anchor-id="categorical-independent-variables">Categorical independent variables</h3>
<p>For exploring the relationship between categorical independent variables and binary outcomes we can just use a normal barchart where the Y-axis is the proportion of the outcome in each category level on the X-axis. Let’s see how to do this for sex:</p>
<ul>
<li>From the main menu go: <mark>Graphs &gt; Chart Builder</mark>. If an information box appears saying “Before you use this dialogue…” just click <mark>OK</mark>. Now in the <mark>Gallery</mark> tab at the middle left click on <mark>Bar</mark> and then double click on the top leftmost picture of a barchart (Simple Bar) to add it to the plot. Next drag the htn variable from the <mark>Variables:</mark> box onto the <mark>Y-Axis?</mark> dotted box on the chart image. Similarly, drag the sex variable onto the <mark>X-Axis?</mark> box. Look to the right of the tool window at the <mark>Element Properties</mark> tab in the <mark>Statistics</mark> box. You should see a drop down menu under <mark>Statistic:</mark>. This should already read “Mean”, but if not click on it and select mean. This tells SPSS to calculate the mean of the Y-axis variable, htn, for each value of the X-axis variable, which are now repeated when in each bin. Now just click <mark>OK</mark>.</li>
</ul>
<p>What can you see?</p>
<p>What does the barchart of sex vs hypertension show?</p>
<details>
<summary>
Read/hide
</summary>
<p>Men appear to have roughly twice the proportion of hypertension cases compared to women.</p>
</details>
<p>In a real analysis you would explore all bivariate relationships this way, but as with the linear regression practical feel free to move on once you are happy with the process.</p>
</section>
<section id="cell-frequencies" class="level3">
<h3 class="anchored" data-anchor-id="cell-frequencies">Cell frequencies</h3>
<p>Unlike with linear regression we have one more data exploration process that we must do. When looking at relationships for a logistic regression model an important issue to look out for is so-called “sparse data”, which means we have small (or empty) “cell sizes”, which really means few (or no) observations of one of the levels of our binary outcome (e.g.&nbsp;either htn = yes or htn = no) in one or more levels of one or more categorical variables (e.g.&nbsp;if say all men were classed as htn = yes). This is explained in more detail during the “Additional potential problems” section below, but briefly if there are zero observations of one outcome level within one or more independent categorical variable levels that will cause the model to fail. If there are just a few you may see very large biased coefficients and confidence intervals. How few is few? There’s not set number, but &lt;5 is often a cause for concern.</p>
<p>We can explore this issue using cross tabulations of the outcome variable against the categorical independent variables.</p>
<ul>
<li>Go: <mark>Analyze &gt; Descriptive Statistics &gt; Crosstabs</mark>. Add htn to the <mark>Row(s):</mark> box and sex, ses and ace to the <mark>Col(s):</mark> box then click <mark>OK</mark>.</li>
</ul>
<p>This will give us three tables, one for each categorical variable. Look at each cross-tabulation cell to see the number of observations in that cell, i.e.&nbsp;each possible combination of the independent categorical variable’s level and the outcome’s level, which for sex vs htn would include 1) male-yes, 2) male-no, 3) female-yes, and 4) female-no. What can you see?</p>
<p>What does the cross-tabulation show?</p>
<details>
<summary>
Read/hide
</summary>
<p>There appear to be reasonable numbers of observations of both levels of the outcome for all levels of sex and ses, but ACE = yes has only three htn = yes observations. See the “Additional potential problems” for more discussion of the possible problems this might cause.</p>
</details>
</section></details>
</section>
</section>
<section id="step-2-run-the-logistic-regression-model" class="level2">
<h2 class="anchored" data-anchor-id="step-2-run-the-logistic-regression-model">Step 2: run the logistic regression model</h2>
<p><a href="https://youtu.be/e1IHf2dX_5U">Video instructions: run the logistic regression model</a></p>
<p><strong>Written instructions: run the logistic regression model</strong></p>
<details>
<summary>
Read/hide
</summary>
<p>We will use SPSS’s <mark>Generalized Linear Model</mark> tool to build our logistic regression model. The generalised linear modelling framework is a more comprehensive and coherent way of (mathematically) representing the full range of possible regression type models, of which linear regression and logistic regression are specific types. SPSS somewhat confusingly and redundantly also has a <mark>Binary Logistic</mark> tool under the <mark>Regression</mark> menu, which will also create a logistic regression model, but like the <mark>Linear</mark> (Regression) tool in the <mark>Regression</mark> menu it is also more restrictive because it won’t accept categorical variables without us first converting them to separate dummy variables, and it also does not offer all the options available in the <mark>Generalized Linear Model</mark> tool.</p>
<ul>
<li><p>From the menu go: <mark>Analyze &gt; Generalized Linear Models</mark>. This will open the <mark>Generalized Linear Models</mark> tool which has multiple tabs along the top of the window.</p></li>
<li><p>In the first tab <mark>Type of Model</mark> look for the <mark>“Binary Response or Events/Trials Data”</mark> set of options and select <mark>Binary logistic</mark>. This tells SPSS we want to create a logistic regression model from among the many other possible generalised linear models (note: linear regression is also a specific type of generalised linear model, and could be run from this tool via the <mark>“Scale Response”</mark> <mark>Linear</mark> option).</p></li>
<li><p>Then click on the <mark>Response</mark> tab and add the htn variable to the <mark>Dependent Variable:</mark> box. Then click on the <mark>Reference Category…</mark> button and under <mark>“Reference Category”</mark> select <mark>First (lowest value)</mark>, which sets the lowest value in the htn variable, 0, as the reference category (i.e.&nbsp;htn = no as the reference category) and click <mark>Continue</mark> (without recoding the outcome variable by changing this option we could make our results refer to the likelihood of not having hypertension if this suited our needs better).</p></li>
<li><p>Then click on the <mark>Predictors</mark> tab and add the categorical variables sex, ses and ace into the <mark>Factors:</mark> box and the numerical variables age, salt and bmi into the <mark>Covariates:</mark> box.</p></li>
<li><p>Then click on the <mark>Model</mark> tab and highlight all the independent variables in the <mark>Factors and Covariates:</mark> box (click on the top one, hold down shift and then click on the bottom one). Then under the <mark>“Build Term(s)”</mark> options ensure the <mark>Type:</mark> is set to <mark>Main effects</mark> (this should be the default) and click the right facing arrow to add the variables into the <mark>Model:</mark> box.</p></li>
<li><p>We will ignore the <mark>Estimation</mark> tab and just accept its defaults (this is where you can alter how the model is estimated).</p></li>
<li><p>Next click on the <mark>Statistics</mark> tab and in the <mark>“Print”</mark> options tick the <mark>Include exponential parameter estimates</mark> box.</p></li>
<li><p>We will ignore the <mark>EM Means</mark> tab and just accept its defaults (this is where you can tell SPSS to calculate certain predicted outcomes given certain contrasts between categorical variable levels other than those displayed by default via dummy coding, i.e.&nbsp;where each level is compared to a reference level).</p></li>
<li><p>Next click on the <mark>Save</mark> tab and tick the <mark>Cook’s distance</mark> option to save a variable of the Cook’s distance values for each observation in the dataset. We’ll come back to this, but it provides a measure of influence of each observation on the values of the regression coefficients.</p></li>
<li><p>Finally click <mark>OK</mark>.</p></li>
</ul>
<p>As with the linear regression practical, before interpreting the results we should check the assumptions of the model are not violated, and if they are make any necessary changes before re-running the model.</p>
</details>
</section>
<section id="step-3-check-the-assumptions-of-the-logistic-regression" class="level2">
<h2 class="anchored" data-anchor-id="step-3-check-the-assumptions-of-the-logistic-regression">Step 3: check the assumptions of the logistic regression</h2>
<p>Unlike with linear regression logistic regression has fewer assumptions and they are not all easily checked. Specifically, logistic regression no longer assumes linearity in the relationship between the independent variables and the outcome, nor does it assume normality or homoscedasticity in the residuals. However, it does have some assumptions as discussed below.</p>
<p><strong>1. Binary outcome</strong></p>
<p>Self-explanatory! However, note that we can code the variable either way around depending on whether we want our results in relation to the likelihood of observing a given “event” or the “non-event”. For example, for our hypertension variable we could obtain results in relation to the likelihood of having hypertension or of not having hypertension if we coded the outcome as 1 = hypertension or 1 = not hypertension respectively, or equivalently we can use the relevant SPSS model building options as explained in the “Step 2: create the logistic regression model” section to change the reference level.</p>
<p><strong>2. Independent observations</strong></p>
<p>As with linear regression logistic regression assumes observations are independent of one another, which we can assume for our study data here as it came from a simple random (cross-sectional) sample. However, if our study design implies this is not the case then we need to either use a method that can cope with this (beyond the scope of this course) or modify our data.</p>
<p>The alternatives aren’t exactly the same as for linear regression though. For longitudinal (multi-time point) data we can again use logistic regression if we just use data from one time point. However, unlike with linear regression we cannot calculate a change value between two time points and analyse that with logistic regression because outcomes of 0-0 and 1-1 at two time points will both give us the same change score, but mean very different things. Similarly if we have nested or clustered observations, such as patients within clinics, we cannot calculate summary outcome values for each cluster, such as means, and use logistic regression as the values will no longer be binary. We may however calculate the proportion of events per cluster and, assuming the assumptions are met, use linear regression to analyse this cluster-level summary (proportion) outcome. Like with linear regression there are multi-level logistic regression models that can explicitly model clustered (or multi-level) data.</p>
<p><strong>3. Linearity of relationships between the log-odds and numerical independent variables</strong></p>
<p>This is similar to the linear regression linearity assumption, but differs in a key way. With logistic regression the model estimates the predicted log-odds of the outcome rather than the actual value of the outcome (0/1), also called the logit transformation of the outcome, for each observation (e.g.&nbsp;individual), given/conditional on the values of the independent variable(s) for that observation. The logistic regression model assumes that there is a linear relationship between any numerical independent variable(s) and the log-odds of the outcome variable. In theory we can test this by looking at the relationship between the residuals and the predicted/fitted values or numerical independent variables, but the resulting plots can be difficult to interpret usefully as you can still get curved patterns but due to the nature of logistic regression not have a model that has violated this assumption. See the following for more discussion:</p>
<ul>
<li><p>https://stats.stackexchange.com/questions/121490/interpretation-of-plot-glm-model</p></li>
<li><p>https://stats.stackexchange.com/questions/45050/diagnostics-for-logistic-regression</p></li>
</ul>
<p>Hence, we won’t produce such plots here and instead recommend that you think very carefully about the model you are building in terms of whether you have allowed for any strong/important non-linear relationships and/or interactions that evidence suggests may be present.</p>
</section>
<section id="step-4-consider-additional-problems" class="level2">
<h2 class="anchored" data-anchor-id="step-4-consider-additional-problems">Step 4: consider additional problems</h2>
<p><strong>1. Adequate sample size</strong></p>
<p>Although you should always consider your sample size when conducting any statistical analysis logistic regression requires more data than a hypothetically equivalent linear regression to achieve the same level of precision in its estimates, because there is less statistical information in an outcome than can only take two values. There are various rules of thumb. A common one is having at least 10 observations (e.g.&nbsp;individuals) that have the <em>least frequent outcome</em> (i.e.&nbsp;that either have the event or do not have the event of interest, depending on whether having the event or not is more common in the sample) for each independent variable in your model. For example, if you have three independent variables and the overall proportion of your least frequent outcome, say not having hypertension, is 0.1, then you would need a minimum sample size of (10 x 3) / 0.1 = 300. All such rules are just rough guides, and it doesn’t mean you can’t build a model with less data, but they give you a good idea about the likely amount of data you need for decent precision. If you do have a much smaller sample size than these guides you’ll typically find you have very wide confidence intervals for all your coefficients, making meaningful inference difficult, and it increases your chances of getting “sparse data” or “complete separation” (see next).</p>
<p><strong>2. No complete separation/sparse data</strong></p>
<p>Complete separation refers to the situation when one or more levels of one or more categorical variables levels have 100% 1s or 100% 0s observed for the outcome (e.g.&nbsp;every male had “hypertension” or did not have “hypertension”). In such a situation a standard logistic regression model cannot estimate the coefficient or standard error for that categorical variable level because there is no statistical variation in the outcome. The solutions are: 1) remove the entire variable, or 2) if possible recode the variable so that you “collapse” or merge two or more category levels together so that all levels have at least one (ideally more) of each possible observation (i.e.&nbsp;a 1 or a 0), but the newly merged category levels must make logical sense for this to be a viable solution.</p>
<p>Sparse data refers to the situation where there are very few 1s or 0s observed in the outcome variable in one or more levels for one or more categorical variable levels (also referred to in this context as “cells”, e.g.&nbsp;the male and female cells for the variable sex). In such a situation with a standard logistic regression model the estimated coefficients and/or standard errors for that categorical variable level will often be very large and biased.</p>
<p>We checked the cell counts for each level of the outcome in the data exploration stage and found there were only 3 htn = yes observations in the ace = yes cell. There are rules of thumb for judging if a cell has sparse data, but really it’s often easiest to just run the model and look at the results and if problems have occurred you will see extremely large (positive or negative) coefficient(s) and standard errors/confidence intervals. You can also check the cell counts for sex and ses if you wish, and you should do this for all categorical variables in a real data analysis situation, or you can move on as we know from earlier data exploration that they are fine.</p>
<p><strong>3. No serious multicollinearity</strong></p>
<p>Again if there is substantial multicollinearity between two or more independent variables this can cause serious problems with the model’s ability to accurately estimate the results. As we are only looking at correlations between the independent variables when assessing multicollinearity we can just use the <mark>Linear Regression</mark> tool to calculate the VIF values again, but there is no need to repeat this process if you don’t want to as the results will be identical to those from the linear regression practical VIF checking (because we have the same set of independent variables). Refer to the “Step 4 consider additional possible issues” section the linear regression practical for more details if needed.</p>
<p><strong>4. No extremely influential observations</strong></p>
<p>Lastly we again need to check that there are no observations that have an excessively influential effect on the results of the logistic regression model. We can again use a version of the Cook’s distance statistic for logistic regression to check which observation(s), if removed, would change the coefficients substantially. When we ran the logistic regression via the <mark>Generalized Linear Model</mark> tool we told SPSS to calculate and save the Cook’s distance values for each observation in a new variable, so as with the linear regression let’s graph these against the observation ID. <mark>Graphs &gt; Legacy Dialogues &gt; Scatter/Dot</mark> and select the <mark>Simple Scatter</mark> option and click <mark>Define</mark>. Add the CooksDistance variable into the <mark>Y Axis:</mark> box and the id variable into the <mark>X Axis:</mark> box and click <mark>OK</mark>.</p>
<p>What do you see?</p>
<p>What do you see on the Cook’s Distance plot?</p>
<details>
<summary>
Read/hide
</summary>
<p>There are two clearly excessively influential points. Interact with the graph to see which observations these are (double click, then click twice on one of the points to highlight it before right clicking and selecting “Go to Case”). Unsurprisingly they are the same two observations that were highly influential for our linear regression: 478 and 520. We can again examine the values of the independent variables for each one again but the conclusion would be the same. Although they have independent variable values that mean the model predicts a very low likelihood of having hypertension we have no reason to think there are any errors in any of their data, and so we must keep them in our primary analysis, but best practice would be to perform a sensitivity analysis by removing them and exploring if our results and therefore our conclusions change substantially, and then transparently reporting this.</p>
</details>
</section>
<section id="step-5-understand-the-results-tables-and-extract-the-key-results" class="level2">
<h2 class="anchored" data-anchor-id="step-5-understand-the-results-tables-and-extract-the-key-results">Step 5: understand the results tables and extract the key results</h2>
<p>As we are now satisfied that the assumptions for our logistic regression model are not violated we can interpret the results. You can either scroll up in your output window or you may wish to re-run the model. By default, SPSS produces a whopping 8 tables, most of which are not that useful for us.</p>
<ul>
<li><p>“Model information” provides some basic information about our model.</p></li>
<li><p>“Case Processing Summary” provides information on how many observations were included and excluded from the model (all those with any missing outcome and/or independent variable data are automatically excluded).</p></li>
<li><p>The “Categorical Variable Information” and “Continuous Variable Information” tables provide descriptive information about all the categorical and continuous (also discrete numerical) variables included.</p></li>
<li><p>“Goodness of Fit” provides information about how well our model fits, or explains, the data. As you can see there are many measures of goodness of fit, and they are of little use to us (they are primarily useful when comparing the fit of different competing models).</p></li>
<li><p>The “Omnibus Test” provides a useful overall test of goodness of fit based on the likelihood ratio. This test compares the fit of our model to the fit of an “intercept only” model, i.e.&nbsp;a logistic regression of the htn variable with no independent variables, just an intercept or overall mean. Clearly, we would hope that our model explains or fits the data much better than an intercept only model, otherwise this is an indication that our independent variables have very little ability to explain variation in the outcome and your model therefore tells you nothing about what influences the outcome. If the p-value (the “Sig.” column of the table) is statistically significant at the 5% level this is usually taken as evidence that the full model has a substantially better fit than the intercept only model. This is commonly reported along with the coefficients.</p></li>
<li><p>The “Test of Model Effects” is analogous to an ANOVA table and tells us which variables (but not separate categorical variable levels) are “statistically significant”, but nothing about their effect sizes or precision. It is therefore of arguably limited value.</p></li>
</ul>
<p>Finally, we get to the key “Parameter Estimates” table, which provides us with very similar analogous information as the linear regression parameter estimates table.</p>
<hr style="border: 3px solid grey">

<p><strong>Parameter estimates table columns explained</strong></p>
<hr style="border: 1px solid grey">

<p><strong>Parameter</strong></p>
<ul>
<li>Again, each row is for a different “parameter” or “logistic regression coefficient”, which means a separate term in the logistic regression model. For numerical variables this means one row per variable. However, because each level of a categorical variable is actually treated as a separate “dummy variable” (coefficient) as standard in a logistic regression model each categorical variable level has its own row.</li>
</ul>
<p><strong>B</strong></p>
<ul>
<li><p>B stands for betas, because in the logistic regression model when represented mathematically the effect (or coefficient) of each variable is usually represented by the Greek letter beta. The betas are more commonly referred to as the parameter estimates or the (logistic regression) coefficients. They tell us the estimated direction (positive or negative) and size of effect each parameter (i.e.&nbsp;variable) in the regression model has on the outcome variable. However, with logistic regression the model parameters as originally estimated by the model are on the log-odds scale. Therefore, for all numerical independent variables they represent the expected mean change in the log-odds of the outcome variable being 1 for every 1-unit increase in the independent variable. For categorical variables with the default dummy coding the coefficients represent the expected mean difference or change in the log-odds of the outcome variable being 1 between each level and the reference level (e.g.&nbsp;male compared to female). Remember by default SPSS sets the category level coded with the highest value as the reference level, and the reference level always has a coefficient value of 0.</p></li>
<li><p>A note on the intercept. Here the intercept now represents the log-odds or odds (for Exp(B)) of the outcome variable being 1 when the values for all numerical independent variables are set to 0, and for the reference levels of all categorical variables. Again, this will often not have a useful interpretation and is often not reported in a logistic regression results table.</p></li>
</ul>
<p><strong>Std. Error</strong></p>
<ul>
<li>These are the standard errors for each coefficient, which estimate the sampling variability of the coefficients in the wider population. This is used when calculating the 95% confidence intervals and p-value.</li>
</ul>
<p><strong>95% Wald Confidence Interval (Lower and Upper)</strong></p>
<ul>
<li>These are the lower and upper 95% confidence intervals for each coefficient based on the Wald method of calculation (essentially assuming a normal distribution).</li>
</ul>
<p><strong>Hypothesis Test (Wald Chi-Square, df and Sig.)</strong></p>
<ul>
<li>This section of the table provides hypothesis tests for each coefficient based on the Wald chi-square statistic and the given degrees of freedom. The p-value is in the “Sig.” column, and is again a two-tailed p-value. Assuming the true value of the coefficient is 0, this p-value represents the probability of obtaining a coefficient at least as great as that observed (positively or negatively) due to sampling error alone.</li>
</ul>
<p><strong>Exp(B)</strong></p>
<ul>
<li><p>These are the exponentiated coefficients, i.e.&nbsp;eβ. Trying typical exp(x) into Google where x is one of the coefficients on the log-odds scale. You will see it is now the Exp(B) value. By exponentiating the coefficients, we can transform them from the log-odds scale the odds ratio scale, which allows for more easily and intuitive interpretation. Therefore, they now have the following interpretations. For numerical variables they represent the multiplicative change in the odds of the outcome variable being 1 for every 1-unit increase in the independent variable. For categorical variables they represent the multiplicative difference in the odds of the outcome variable being 1 for each level of the categorical variable compared to the reference level. By multiplicative we mean on the multiplicative scale, so an odds ratio of 2 means the odds are multiplied by 2 (i.e.&nbsp;double) for every 1-unit increase in a numerical variable or compared to the reference level of a categorical variable. Similarly, an odds ratio of 0.5 means the odds are multiplied by 0.5 (i.e.&nbsp;halve) for every 1-unit increase in a numerical variable or compared to the reference level of a categorical variable. Therefore, on the multiplicative scale the null or no effect value is 1.</p></li>
<li><p>A note on the intercept. Here the intercept now represents the odds (for Exp(B)) of the outcome variable being 1 when the values for all numerical independent variables are set to 0, and for the reference levels of all categorical variables. Again, this will often not have a useful interpretation and is often not reported in a logistic regression results table.</p></li>
</ul>
<p><strong>95% Wald Confidence Interval for Exp(B) (Lower and Upper)</strong></p>
<ul>
<li>These are the (Wald-based) 95% confidence intervals for the exponentiated coefficients, i.e.&nbsp;for the estimated odds ratios.</li>
</ul>
<p>Note: typically, only the exponentiated coefficients (and their 95% confidence intervals) are presented in the results from a logistic regression model, due to them being much easier and more intuitive (but still not that intuitive!) to interpret than those on the original log-odds scale.</p>
<hr style="border: 1px solid grey">

</section>
<section id="step-6-report-and-interpret-the-results" class="level2">
<h2 class="anchored" data-anchor-id="step-6-report-and-interpret-the-results">Step 6: report and interpret the results</h2>
<p>Let’s see how we interpret some the results in the parameter estimates table. We will only look at the exponentiated coefficients, i.e.&nbsp;the odds ratios regression coefficients, and their confidence intervals as they are more easily interpreted and, as explained above, only the odds ratio scale results are typically presented instead of the original scale log-odds results. We’ll also keep things briefer than for the same linear regression sections as most of the concepts apply here in the same way, but we’re just dealing with ratio measures of relationships rather than differences/increases/decreases.</p>
<section id="understanding-and-interpreting-odds-ratios" class="level3">
<h3 class="anchored" data-anchor-id="understanding-and-interpreting-odds-ratios">Understanding and interpreting odds ratios</h3>
<p>Odds ratios are just ratios, like risk ratios, but when interpreting their direction and size mistakes can be easily made. First of all, unlike linear regression coefficients which can range (in theory) from negative infinity to positive infinity, odds ratios can range (in theory) from 0 to positive infinity. Because they are ratios the null value or no relationship/no effect value is 1, not 0 like for linear regression coefficients. This is because ratios are the result of dividing two numbers, so if those numbers are the same then the result is 1, whereas with linear regression the coefficients are differences, where a difference of 0 represents no difference. Therefore, odds ratios &lt;1 represent a negative relationship and odds ratios &gt;1 represent a positive relationship.</p>
<p>As odds ratios are ratios they are on the “multiplicative scale”, and they therefore represent factors by which one set of odds is multiplicatively related to another. For example, an odds ratio of 2 indicates that the odds of an outcome in the group of interest are 2 times the odds of the outcome occurring in the reference or comparison group. Take care though. It is not correct to say that an odds ratio of 2 indicates that the odds in the group of interest are 2 times <em>higher</em> than the odds in the reference group. To talk about odds ratios in terms of the odds for the group of interest being relatively higher or lower than the odds for the reference group you should first convert the odds ratio to a percentage using the following formulae:</p>
<blockquote class="blockquote">
<p>When the odds ratio is &gt;1 you can calculate the % increase in odds as:</p>
</blockquote>
<blockquote class="blockquote">
<p><strong>(OR – 1) x 100</strong></p>
</blockquote>
<blockquote class="blockquote">
<p>For example, for an odds ratio of 4.2:</p>
</blockquote>
<blockquote class="blockquote">
<p><strong>(4.2 – 1) x 100 = 320% increase in odds</strong></p>
</blockquote>
<blockquote class="blockquote">
<p>When the odds ratio is &lt;1 you can calculate the % decrease in odds as:</p>
</blockquote>
<blockquote class="blockquote">
<p><strong>(1 – OR) x 100</strong></p>
</blockquote>
<blockquote class="blockquote">
<p>For example, for an odds ratio of 0.45:</p>
</blockquote>
<blockquote class="blockquote">
<p><strong>(1 – 0.45) x 100 = 55% decrease in odds</strong></p>
</blockquote>
<p>Note: you should of course refer to the upper and lower odds ratio confidence interval range when discussing results, and those values can be similarly transformed as above if desired.</p>
<p>Let’s look at some examples to make this all clearer. We’ll start with categorical independent variables as these are arguably easier to interpret than numerical independent variables.</p>
</section>
<section id="categorical-variables" class="level3">
<h3 class="anchored" data-anchor-id="categorical-variables">Categorical variables</h3>
<blockquote class="blockquote">
<p>With the standard dummy coding of categorical variables (https://stats.idre.ucla.edu/spss/faq/coding-systems-for-categorical-variables-in-regression-analysis-2/) logistic regression coefficients for categorical variables represent the model-predicted mean (or more loosely the average) <em>ratio</em> between the odds of the outcome for the categorical level (or group) of interest compared to the odds of the outcome for the reference or comparison level (or group), while holding the effect of all other independent variables constant, i.e.&nbsp;they measure the mean independent relationship. The choice of which categorical level is set as the reference group is up to you.</p>
</blockquote>
<p>Let’s take sex as an example. In the parameter estimates table the adjusted odds ratio and confidence interval for the category level male compared to the category level female was AOR = 3.53 (95% CI: 2, 6.27). Note: AOR = adjusted odds ratio, because the odds ratio is adjusted for all other independent variables in the model. Therefore, the model predicts that males have odds of having hypertension that are 3.53 times the odds of having hypertension for females, or equivalently the model predicts that males have odds of having hypertension that are 254% higher than the odds of having hypertension for females, while holding the effect of all other independent variables constant. The 95% confidence intervals then tell us that the odds ratio for having hypertension in males compared to females is likely to be between 2 and 6.27 in the target population. Therefore, we have a reasonably accurate/precise estimate of this relationship. However, as always this is conditional on the level of bias in the results.</p>
</section>
<section id="numerical-variables" class="level3">
<h3 class="anchored" data-anchor-id="numerical-variables">Numerical variables</h3>
<p>Here are four <em>equivalent</em> ways to interpret a logistic regression odds ratio coefficient for a numerical independent variable (i.e.&nbsp;you can use any of these so it makes sense to use the one you are most comfortable with):</p>
<blockquote class="blockquote">
<p>Logistic regression coefficients for numerical independent variables represent the model-predicted mean (or more loosely the average) <em>ratio</em> between the odds of the outcome for a 1-unit increase in the independent variable compared to the odds of the outcome without a 1-unit increase in the independent variable, while holding the effect of all other independent variables constant, i.e.&nbsp;they measure the mean independent relationship.</p>
</blockquote>
<blockquote class="blockquote">
<p>Or you may find it easier to think in terms of the multiplicative change in the odds for every 1-unit increase in the independent variable: logistic regression coefficients for numerical independent variables represent the model-predicted mean (or more loosely the average) <em>multiplicative change</em> in the odds of the outcome for every 1-unit increase in the independent variable, while holding the effect of all other independent variables constant.</p>
</blockquote>
<blockquote class="blockquote">
<p>Or you may find it easier to think in terms of the number of times the odds change for every 1-unit increase in the independent variable: logistic regression coefficients for numerical independent variables represent the model-predicted mean (or more loosely the average) number of times the odds of the outcome change for every 1-unit increase in the independent variable, while holding the effect of all other independent variables constant. Therefore, for any given odds ratio “OR” regression coefficient for a numerical independent variable you can say that “the model-predicts that the odds of the outcome change OR times for every 1-unit increase in the independent variable, while holding the effect of all other independent variables constant.”</p>
</blockquote>
<blockquote class="blockquote">
<p>Or you can convert the odds ratio to a percentage change in the odds (i.e.&nbsp;percentage increase or decrease in the odds) using the formulae above and interpret it in those terms: logistic regression coefficients for numerical independent variables represent the model-predicted mean (or more loosely the average) percentage change in the odds of the outcome for every 1-unit increase in the independent variable, while holding the effect of all other independent variables constant.</p>
</blockquote>
<p>I usually prefer to use either the third or final interpretation/wording.</p>
<p>Note: for all these equivalent interpretation the ratio/change/relationship does not depend on the value of the independent variable, i.e.&nbsp;the same ratio/change/relationship is assumed to exist across the full range of values that the independent variable can take in the sample data, but it should not be considered to hold if you were considering values of the independent variable outside of the range of values seen in the sample data.</p>
<p>Let’s take salt intake (in grams/day) as an example. From the parameter estimates table we can see the odds ratio for this numerical independent variable is AOR = 0.96 (95% CI: 0.85, 1.14). Therefore, the model predicts that the odds of having hypertension change 0.96 times for every extra gram of salt consumed per day, while holding the effect of all other independent variables constant. Or equivalently the model predicts that the odds of having hypertension decrease by 4% for every extra gram of salt consumed per day, while holding the effect of all other independent variables constant. The 95% confidence intervals imply that the odds ratio in the target population is between 0.85 and 1.14, and therefore we cannot be confident whether the true relationship in the target population is positive or negative, although we can be confident that the true odds ratio is unlikely to be very large whether positively or negatively. As always though this is conditional on the level of bias in the results.</p>
</section>
<section id="practical-importance" class="level3">
<h3 class="anchored" data-anchor-id="practical-importance">Practical importance</h3>
<p>Similar considerations apply when trying to interpret the practical importance of the results of a logistic regression analysis of a study as those discussed for a linear regression. Therefore, see the discussion about interpreting the practical importance of numerical independent variables and categorical independent variables in the linear regression practical notes above (in particular see the “Numerical variables” section).</p>
<p>However, as shown in the lecture on logistic regression, it is also much more difficult to interpret the results of a logistic regression in terms of the real world importance for clinical/public health practice and policy etc than those from a linear regression for two reasons.</p>
<p>First, odds ratios are relative measures of a relationship and you cannot interpret their absolute impact without knowing what the odds (or probability/prevalence) of the outcome are in the reference group. Therefore, an odds ratio of 100 might not represent much of an absolute increase in the probability of occurrence of some event if that event is rare, while an odds ratio of 2 might represent a large absolute increase in the probability of occurrence of some event if that event is common. For example, if the probability of developing a rare cancer is 0.001% then a risk factor that increased the odds of developing the cancer 100 times (i.e.&nbsp;an odds ratio of 100) would only result in a probability of developing the cancer 0.1%. While if the probability of developing a common cancer is 25% then a risk factor that increased the odds of developing the cancer just 2 times (i.e.&nbsp;an odds ratio of 2) would result in a probability of developing the cancer of 40%.</p>
<p>Second, odds ratios are ratios of odds, and for most people odds are not as intuitive as probabilities of an outcome. However, we can use the following formula to approximate the relative risk (or risk ratio), which is arguably more easily interpreted as it’s in terms of the probabilities of the outcome:</p>
<blockquote class="blockquote">
<p>Approximate relative risk = adjusted or crude odds ratio / (1 − p0 + (p0 x adjusted orcrude odds ratio))</p>
</blockquote>
<p>As explained in the lecture the adjusted/crude odds ratio is the adjusted/crude odds ratio for the independent variable of interest (it will only be a crude estimate if the independent variable of interest is the only independent variable in the model), while p0 is the risk in the baseline/reference/control/comparison group. Also as explained in the lecture, in an observational study with multiple variables in a logistic regression model p0 will vary depending on both the value of the independent variable of interest and all other independent variables. Therefore, in such a situation we can try and estimate a range (lower and upper value) of plausible baseline risks to use in the calculation along with the range of adjusted odds ratios implied by the 95% confidence interval of the adjusted odds ratio. We will not look not at this further here, but be aware of the challenges with interpreting results from logistic regression models in practice, and if you plan to use logistic regression (and indeed sophisticated analyses more generally) frequently in the future then the best advice is to learn how to do them in <em>R</em> (free) or <em>Stata</em> where you can then use their functions for estimating predicted probabilities of the outcome at different values of the independent variables, making it very easy to calculate risk ratios or even better risk differences along with the actual predicted probabilities, making for much more intuitive practical interpretation of your model results!</p>
</section>
<section id="non-significant-results" class="level3">
<h3 class="anchored" data-anchor-id="non-significant-results">“Non-significant results”</h3>
<p>The same advice applies when reporting and discussing non-significant results from a logistic regression as for a linear regression. Therefore, see the “‘Non-significant results’” section in the linear regression practical session for details.</p>
</section>
<section id="regression-tables" class="level3">
<h3 class="anchored" data-anchor-id="regression-tables">Regression tables</h3>
<p>The same advice applies when reporting and presenting results from a logistic regression as for a linear regression in terms of presentation via a table. Therefore, see the “Regression tables” section in the linear regression practical session for details. However, an additional comment would that it is most common for logistic regression results table to just present the exponentiated regression coefficients, i.e.&nbsp;the odds ratio scale regression coefficients, rather than the original log-odds scale regression coefficients, which are harder to usefully interpret. You should always make it explicit and clear though what form of results you are presenting. You can always include these in the same table or a separate table (e.g.&nbsp;as supplementary materials) if you need to. Also, there are various pseudo-R²s for logistic regression, but they are often criticised for their less than ideal meaning and interpretability. Hence, unless required you do not need to present an “equivalent” R² value. However, it is usually recommended to present the likelihood ratio (chi-square) test result p-value, which compares your model to an intercept-only model, as this at least indicates whether your model explains more variation in the data than a simple intercept-only model.</p>
</section>
<section id="methods" class="level3">
<h3 class="anchored" data-anchor-id="methods">Methods</h3>
<p>As usual in a methods section you should clearly explain why you used a logistic regression analysis and exactly what you did, including how all the variables were coded/what units they were in, if you modified any variables, how you dealt with any missing data etc.</p>
</section>
</section>
<section id="exercise-multiple-logistic-regression" class="level2">
<h2 class="anchored" data-anchor-id="exercise-multiple-logistic-regression">Exercise: multiple logistic regression</h2>
<ul>
<li>In the MSc &amp; MPH computer practical sessions files “Exercises” folder open the “Exercises.docx” Word document and scroll down to <strong>Multiple logistic regression: the causes of variation in hypertension status</strong>. Then follow the instructions in the exercise.</li>
</ul>
<p><strong>Example completed logistic regression results table</strong></p>
<details>
<summary>
Read/hide
</summary>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Images/Logistic regression table.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Logistic regression results table</figcaption>
</figure>
</div>
</details>
<p><strong>Example statistical and practical interpretation of the relationship between BMI and hypertension status</strong></p>
<details>
<summary>
Read/hide
</summary>
<p>The model-predicted that the odds of having hypertension increased by 85% (95% CI: 64%, 110%) for every 1-unit increase in BMI (kg/m²), while holding the effect of all other independent variables constant. Therefore, there was a clear, statistically significant, positive relationship between BMI and hypertension status.</p>
</details>
<p><strong>Example statistical and practical interpretation of the relationship between socio-economic status and hypertension status</strong></p>
<details>
<summary>
Read/hide
</summary>
<p>The model-predicted that, on average, the odds of having hypertension for individuals in the low socio-economic group were 187% (95% CI: 28%, 543%) higher than the odds of having hypertension for individuals in the high socio-economic group, while, on average, the odds of having hypertension for individuals in the medium socio-economic group were 38% (95% CI: -42%, 233%) higher than the odds of having hypertension for individuals in the high socio-economic group. <em>Note: as the lower confidence interval was for an odds ratio &lt;1 it represents a percentage reduction in the odds and so you must indicate this by adding a negative symbol. You wouldn’t have to do this if both confidence intervals were reductions if you had verbally stated that the percentage changes were “reduction” or “decreases”, as doing both could be confusing (a double negative).</em> Therefore, there was a clear, statistically significant, positive relationship between having low socio-economic status compared to high socio-economic status and the odds of having hypertension, but no clear (“statistically non-significant”) relationship between having medium socio-economic status compared to high socio-economic status and the odds of having hypertension.</p>
</details>
<p><strong>Example text discussing the key limitations of the study and the issues that must be considered when critically interpreting the results</strong></p>
<details>
<summary>
Read/hide
</summary>
<p>Care must be taken when interpreting the results because the study was an observational cross-sectional study with therefore very limited ability to make robust causal inferences, and because the validity and accuracy of the results depends on how well the study data and model have accurately captured the causal relationships of interest and all important confounding variables of those causal relationships, and on how much bias there was in the study.</p>
</details>
</section>
<section id="next-steps-optional" class="level2">
<h2 class="anchored" data-anchor-id="next-steps-optional">Next steps (optional)</h2>
<p>If you have time you can run a sensitivity analysis for the excessively influential points 478 and 520. Delete the htn values for these observations (which will exclude all their data from the model) and re-run the model.</p>
<p>What happens to the results?</p>
<details>
<summary>
Read/hide
</summary>
<p>Although there are some minor changes, with the largest being for the effect of taking an ACE inhibitor, it seems fair to say there are no substantial changes to the interpretation of the results. You can therefore have greater confidence in the robustness of the primary results.</p>
</details>


</section>


</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>